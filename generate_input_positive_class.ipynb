{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate input for positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from lxml import etree\n",
    "import json\n",
    "from utils_functions import get_term_occurrences_from_ene, load_lexicon, get_ngrams_wt_term_outside_ene\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create the lexicon from terms embedded in ENE from Perdido XML-TEI\n",
    "\n",
    "\\<rs type=\"place\">\\<term type=\"place\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Corpus Traitement Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/lmoncla/Documents/Data/Corpus/Choucas/Perdido'\n",
    "output_filename = 'Traitement_Texte_pivot_lexicon'\n",
    "\n",
    "words_TT = []\n",
    "for doc in tqdm(sorted(os.listdir(path))):\n",
    "    filename = os.path.join(path, doc, doc+'.xml') # version Traitements_Texte\n",
    "    words_TT.extend(get_term_occurrences_from_ene(filename))\n",
    "\n",
    "# list to dict with frequency\n",
    "frequency_dict_geo_TT = {value: words_TT.count(value) for value in words_TT}\n",
    "print('Size of the lexicon', len(frequency_dict_geo_TT))\n",
    "\n",
    "#save the dict in file\n",
    "with open(output_filename + '.json', 'w') as fp:\n",
    "    json.dump(frequency_dict_geo_TT, fp, ensure_ascii=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Corpus Visorando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/lmoncla/Documents/Data/Corpus/Visorando/Perdido'\n",
    "output_filename = 'Visorando_pivot_lexicon'\n",
    "\n",
    "words_viso = []\n",
    "for doc in tqdm(sorted(os.listdir(path))):\n",
    "    filename = os.path.join(path, doc[:-4]+'.xml') # version visorando\n",
    "    words_viso.extend(get_term_occurrences_from_ene(filename))\n",
    "\n",
    "# list to dict with frequency\n",
    "frequency_dict_geo_viso = {value: words_viso.count(value) for value in words_viso}\n",
    "print('Size of the lexicon', len(frequency_dict_geo_viso))\n",
    "\n",
    "#save the dict in file\n",
    "with open(output_filename + '.json', 'w') as fp:\n",
    "    json.dump(frequency_dict_geo_viso, fp, ensure_ascii=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Lexique TT - Viso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [item for item in frequency_dict_geo_viso.keys() if item not in frequency_dict_geo_TT.keys()]\n",
    "print(813-190)\n",
    "print(len(words), words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Lexicons preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in frequency_dict_geo_viso.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dict from file\n",
    "# only necessery if you want to run the next section and not the previous one (adapt output_filename)\n",
    "\n",
    "frequency_dict_geo_viso = load_lexicon(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Find occurrences of the lexicon in the corpus (outside ENE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Corpus Traitement text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/lmoncla/Documents/Data/Corpus/Choucas/Perdido'\n",
    "\n",
    "#lexicon = frequency_dict_geo_TT\n",
    "lexicon = frequency_dict_geo_viso\n",
    "\n",
    "json_content = []\n",
    "ngram_id = 1\n",
    "for doc in sorted(os.listdir(path)):\n",
    "    filename = os.path.join(path, doc, doc+'.xml') # version Traitements_Texte\n",
    "    json_content.extend(get_ngrams_wt_term_outside_ene(filename, lexicon, ngram_id))\n",
    "\n",
    "print('number of ngram',len(json_content))\n",
    "\n",
    "name = 'Traitement_Texte_class1'\n",
    "with open(name + \".json\", \"w\") as outfile:\n",
    "    json.dump(json_content,outfile, ensure_ascii=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Corpus Visorando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/lmoncla/Documents/Data/Corpus/Visorando/Perdido'\n",
    "json_content = []\n",
    "ngram_id = 1\n",
    "for doc in sorted(os.listdir(path)):\n",
    "    filename = os.path.join(path, doc[:-4]+'.xml') # version visorando\n",
    "    json_content.extend(get_ngrams_wt_term_outside_ene(filename, frequency_dict_geo_viso, ngram_id))\n",
    "                            \n",
    "print('number of ngram',len(json_content))\n",
    "\n",
    "name = 'Visorando_class1'\n",
    "with open(name + \".json\", \"w\") as outfile:\n",
    "    json.dump(json_content,outfile, ensure_ascii=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 TT - Viso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/lmoncla/Documents/Data/Corpus/Choucas/Perdido'\n",
    "\n",
    "json_content = []\n",
    "ngram_id = 1\n",
    "for doc in sorted(os.listdir(path)):\n",
    "    filename = os.path.join(path, doc, doc+'.xml') # version Traitements_Texte\n",
    "    json_content.extend(get_ngrams_wt_term_outside_ene(filename, words, ngram_id))\n",
    "\n",
    "print('number of ngram',len(json_content))\n",
    "\n",
    "name = 'TT-viso_class1'\n",
    "with open(name + \".json\", \"w\") as outfile:\n",
    "    json.dump(json_content,outfile, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = set([ngram['pivot']for ngram in json_content])\n",
    "len(l)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tests with ngrams with pivot at different positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/lmoncla/Documents/Data/Corpus/Choucas/Perdido'\n",
    "\n",
    "lexicon = frequency_dict_geo_TT\n",
    "#lexicon = frequency_dict_geo_viso\n",
    "position = 7\n",
    "json_content = []\n",
    "ngram_id = 1\n",
    "for doc in sorted(os.listdir(path)):\n",
    "    filename = os.path.join(path, doc, doc+'.xml') # version Traitements_Texte\n",
    "    json_content.extend(get_ngrams_wt_term_outside_ene(filename, lexicon, ngram_id, position=position))\n",
    "\n",
    "print('number of ngram',len(json_content))\n",
    "\n",
    "name = 'Traitement_Texte_class1_position'+str(position)\n",
    "with open(name + \".json\", \"w\") as outfile:\n",
    "    json.dump(json_content,outfile, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the list of terms in ENE not categorized by Perdido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for doc in tqdm(sorted(os.listdir(path))):\n",
    "    filename = os.path.join(path, doc, doc+'.xml') \n",
    "    if os.path.exists(filename):\n",
    "        tree = etree.parse(filename)\n",
    "\n",
    "        for term in tree.xpath('.//rs[@type=\"unknown\" and @subtype=\"ene\"]/term[@type=\"unknown\"]'):\n",
    "            phrase = ''\n",
    "            for w in term.xpath('.//w[@pos=\"N\" or @pos=\"PREPDET\" or @pos=\"PREP\"]'):\n",
    "                phrase += w.text.lower() + ' '\n",
    "                #print(w.text, end=' ')\n",
    "            words.append(phrase.strip())\n",
    "            #print()\n",
    "\n",
    "# list to dict with frequency\n",
    "frequency_dict_unknown = {value: words.count(value) for value in words}\n",
    "print('Size of the lexicon', len(frequency_dict_unknown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_dict_unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of files with rs in term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/lmoncla/Documents/Data/Corpus/Visorando/Perdido'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for doc in tqdm(sorted(os.listdir(path))):\n",
    "    filename = os.path.join(path, doc+'.xml') \n",
    "    if os.path.exists(filename):\n",
    "        tree = etree.parse(filename)\n",
    "\n",
    "\n",
    "        for term in tree.xpath('.//term//rs'):\n",
    "            print(filename)\n",
    "            phrase = ''\n",
    "            for w in term.xpath('.//w'):\n",
    "                phrase += w.text.lower() + ' '\n",
    "        #print(phrase, end=' ')\n",
    "        #print()\n",
    "            \n",
    "            #print()\n",
    "\n",
    "        # list to dict with frequency\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
